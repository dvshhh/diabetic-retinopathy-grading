{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEJvDW_SOt7j",
        "outputId": "5b9ed024-71d7-4640-d4fe-7e3972fa4925"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install git+https://github.com/qubvel/segmentation_models\n",
        "# pip install git+https://github.com/qubvel/segmentation_models\n",
        "!pip install efficientnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBZDpiryCaHX",
        "outputId": "52f03022-54cb-4782-f295-b5d204a3a220"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.22.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.8.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (23.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.25.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2023.4.12)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.10.1)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Add, Multiply, Reshape, Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "from efficientnet.tfkeras import EfficientNetB3\n",
        "# from tensorflow.keras.applications import EfficientNetB3\n",
        "from tensorflow.keras.optimizers import AdamW"
      ],
      "metadata": {
        "id": "jq-E--y4UpX2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "x_train = np.load('/content/drive/MyDrive/np_images/x_train.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/np_images/y_train.npy')\n",
        "x_test = np.load('/content/drive/MyDrive/np_images/x_test.npy')\n",
        "y_test = np.load('/content/drive/MyDrive/np_images/y_test.npy')"
      ],
      "metadata": {
        "id": "PRCQq72LUsXQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def preprocess_image(img):\n",
        "\n",
        "#     img=np.load(img)\n",
        "#     # Crop the center 80% of the image\n",
        "#     height, width, channels = img.shape\n",
        "#     crop_height = int(height * 0.8)\n",
        "#     crop_width = int(width * 0.8)\n",
        "#     start_height = int((height - crop_height) / 2)\n",
        "#     start_width = int((width - crop_width) / 2)\n",
        "#     img = img[start_height:start_height+crop_height, start_width:start_width+crop_width, :]\n",
        "    \n",
        "#     # Apply Gaussian blur with kernel size 3\n",
        "#     img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "    \n",
        "#     # Rescale the pixel values to [0, 1]\n",
        "    \n",
        "#     return img"
      ],
      "metadata": {
        "id": "9022aGJ5eo_h"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# from matplotlib import pyplot as plt\n",
        "# import cv2 # for image pre-processing\n",
        "# import gc\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# #preprocessed_x_train = np.empty((len(x_train), 256, 256, 3), dtype=np.float32)\n",
        "\n",
        "# for i in range(len(x_train)):\n",
        "#     img = x_train[i]\n",
        "#     img = preprocess_image(img)\n",
        "#     img = cv2.resize(img, (224, 224))\n",
        "#     x_train[i] = img\n",
        "\n",
        "# # preprocessed_x_test = np.empty((len(x_test), 256, 256, 3), dtype=np.float32)\n",
        "\n",
        "# for i in range(len(x_test)):\n",
        "#     img = x_test[i]\n",
        "#     img = preprocess_image(img)\n",
        "#     img = cv2.resize(img, (224, 224))\n",
        "#     x_test[i] = img"
      ],
      "metadata": {
        "id": "ljwKzcY4e0ci"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resize\n",
        "x_train = tf.image.resize(x_train, size=(224, 224)) / 255.0\n",
        "x_test = tf.image.resize(x_test, size=(224, 224)) / 255.0"
      ],
      "metadata": {
        "id": "-DSoSP1DUve8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "MB0xESRpZuLE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img):\n",
        "    # Crop the center 80% of the image\n",
        "    #print(img.shape)\n",
        "    height, width, channels = img.shape\n",
        "    crop_height = int(height * 0.8)\n",
        "    crop_width = int(width * 0.8)\n",
        "    start_height = int((height - crop_height) / 2)\n",
        "    start_width = int((width - crop_width) / 2)\n",
        "    img = img[start_height:start_height+crop_height, start_width:start_width+crop_width, :]\n",
        "    \n",
        "    # Apply Gaussian blur with kernel size 3\n",
        "    img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    \n",
        "    # Rescale the pixel values to [0, 1]\n",
        "    img = img / 255.\n",
        "    \n",
        "    # Rescale the pixel values to [0, 1]\n",
        "    \n",
        "    return img"
      ],
      "metadata": {
        "id": "pxh7RQanWhL5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZYuQDzgBsnk",
        "outputId": "92ffe286-5f3a-4b06-faae-a43237cb76aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image data augmentated ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.AdamW.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "92/92 [==============================] - 30s 198ms/step - loss: 0.9305 - accuracy: 0.6603 - f1: 0.2180 - val_loss: 0.7913 - val_accuracy: 0.7203 - val_f1: 0.2369\n",
            "Epoch 2/100\n",
            "92/92 [==============================] - 13s 141ms/step - loss: 0.7824 - accuracy: 0.7139 - f1: 0.2875 - val_loss: 0.7371 - val_accuracy: 0.7394 - val_f1: 0.2174\n",
            "Epoch 3/100\n",
            "92/92 [==============================] - 13s 141ms/step - loss: 0.7414 - accuracy: 0.7228 - f1: 0.3061 - val_loss: 0.7184 - val_accuracy: 0.7353 - val_f1: 0.3357\n",
            "Epoch 4/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.7165 - accuracy: 0.7310 - f1: 0.3237 - val_loss: 0.7017 - val_accuracy: 0.7449 - val_f1: 0.2997\n",
            "Epoch 5/100\n",
            "92/92 [==============================] - 13s 143ms/step - loss: 0.6955 - accuracy: 0.7269 - f1: 0.3265 - val_loss: 0.6824 - val_accuracy: 0.7476 - val_f1: 0.3688\n",
            "Epoch 6/100\n",
            "92/92 [==============================] - 13s 142ms/step - loss: 0.6811 - accuracy: 0.7412 - f1: 0.3437 - val_loss: 0.6994 - val_accuracy: 0.7462 - val_f1: 0.3272\n",
            "Epoch 7/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.6778 - accuracy: 0.7392 - f1: 0.3505 - val_loss: 0.6798 - val_accuracy: 0.7367 - val_f1: 0.3443\n",
            "Epoch 8/100\n",
            "92/92 [==============================] - 13s 143ms/step - loss: 0.6378 - accuracy: 0.7508 - f1: 0.3729 - val_loss: 0.6896 - val_accuracy: 0.7394 - val_f1: 0.3858\n",
            "Epoch 9/100\n",
            "92/92 [==============================] - 13s 143ms/step - loss: 0.6410 - accuracy: 0.7521 - f1: 0.3616 - val_loss: 0.6582 - val_accuracy: 0.7435 - val_f1: 0.3837\n",
            "Epoch 10/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.6271 - accuracy: 0.7658 - f1: 0.3793 - val_loss: 0.6753 - val_accuracy: 0.7449 - val_f1: 0.3794\n",
            "Epoch 11/100\n",
            "92/92 [==============================] - 13s 143ms/step - loss: 0.6120 - accuracy: 0.7631 - f1: 0.3940 - val_loss: 0.6624 - val_accuracy: 0.7544 - val_f1: 0.3979\n",
            "Epoch 12/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.6188 - accuracy: 0.7648 - f1: 0.4021 - val_loss: 0.6866 - val_accuracy: 0.7490 - val_f1: 0.4021\n",
            "Epoch 13/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.6050 - accuracy: 0.7610 - f1: 0.4053 - val_loss: 0.6807 - val_accuracy: 0.7490 - val_f1: 0.3846\n",
            "Epoch 14/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5912 - accuracy: 0.7689 - f1: 0.4237 - val_loss: 0.6641 - val_accuracy: 0.7476 - val_f1: 0.3792\n",
            "Epoch 15/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.5942 - accuracy: 0.7593 - f1: 0.3936 - val_loss: 0.6567 - val_accuracy: 0.7572 - val_f1: 0.4186\n",
            "Epoch 16/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5918 - accuracy: 0.7620 - f1: 0.4184 - val_loss: 0.6513 - val_accuracy: 0.7681 - val_f1: 0.3849\n",
            "Epoch 17/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5804 - accuracy: 0.7723 - f1: 0.4333 - val_loss: 0.6552 - val_accuracy: 0.7476 - val_f1: 0.3559\n",
            "Epoch 18/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.5632 - accuracy: 0.7808 - f1: 0.4374 - val_loss: 0.6449 - val_accuracy: 0.7640 - val_f1: 0.4096\n",
            "Epoch 19/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.5731 - accuracy: 0.7853 - f1: 0.4710 - val_loss: 0.6721 - val_accuracy: 0.7613 - val_f1: 0.3939\n",
            "Epoch 20/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.5433 - accuracy: 0.7873 - f1: 0.4551 - val_loss: 0.6678 - val_accuracy: 0.7585 - val_f1: 0.4436\n",
            "Epoch 21/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.5429 - accuracy: 0.7832 - f1: 0.4711 - val_loss: 0.6763 - val_accuracy: 0.7503 - val_f1: 0.4065\n",
            "Epoch 22/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5351 - accuracy: 0.7866 - f1: 0.4751 - val_loss: 0.6781 - val_accuracy: 0.7640 - val_f1: 0.4186\n",
            "Epoch 23/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5507 - accuracy: 0.7873 - f1: 0.4696 - val_loss: 0.6616 - val_accuracy: 0.7544 - val_f1: 0.4041\n",
            "Epoch 24/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5351 - accuracy: 0.7866 - f1: 0.4665 - val_loss: 0.6411 - val_accuracy: 0.7681 - val_f1: 0.4456\n",
            "Epoch 25/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5205 - accuracy: 0.7917 - f1: 0.5169 - val_loss: 0.6784 - val_accuracy: 0.7667 - val_f1: 0.4435\n",
            "Epoch 26/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5151 - accuracy: 0.8013 - f1: 0.4995 - val_loss: 0.6599 - val_accuracy: 0.7585 - val_f1: 0.4567\n",
            "Epoch 27/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5201 - accuracy: 0.7992 - f1: 0.5036 - val_loss: 0.6605 - val_accuracy: 0.7558 - val_f1: 0.4386\n",
            "Epoch 28/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.5005 - accuracy: 0.7996 - f1: 0.5195 - val_loss: 0.6427 - val_accuracy: 0.7640 - val_f1: 0.4698\n",
            "Epoch 29/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5243 - accuracy: 0.7958 - f1: 0.5090 - val_loss: 0.6786 - val_accuracy: 0.7558 - val_f1: 0.4359\n",
            "Epoch 30/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.5065 - accuracy: 0.8030 - f1: 0.5182 - val_loss: 0.6653 - val_accuracy: 0.7626 - val_f1: 0.4696\n",
            "Epoch 31/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4766 - accuracy: 0.8115 - f1: 0.5363 - val_loss: 0.6858 - val_accuracy: 0.7667 - val_f1: 0.4390\n",
            "Epoch 32/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.5073 - accuracy: 0.7952 - f1: 0.5147 - val_loss: 0.6568 - val_accuracy: 0.7585 - val_f1: 0.4453\n",
            "Epoch 33/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4814 - accuracy: 0.8129 - f1: 0.5349 - val_loss: 0.6930 - val_accuracy: 0.7681 - val_f1: 0.4446\n",
            "Epoch 34/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4841 - accuracy: 0.8132 - f1: 0.5480 - val_loss: 0.6581 - val_accuracy: 0.7735 - val_f1: 0.4420\n",
            "Epoch 35/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4736 - accuracy: 0.8150 - f1: 0.5595 - val_loss: 0.6526 - val_accuracy: 0.7708 - val_f1: 0.4316\n",
            "Epoch 36/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4568 - accuracy: 0.8300 - f1: 0.5789 - val_loss: 0.6802 - val_accuracy: 0.7517 - val_f1: 0.4779\n",
            "Epoch 37/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4854 - accuracy: 0.8074 - f1: 0.5465 - val_loss: 0.7086 - val_accuracy: 0.7353 - val_f1: 0.4307\n",
            "Epoch 38/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4605 - accuracy: 0.8201 - f1: 0.5778 - val_loss: 0.7056 - val_accuracy: 0.7558 - val_f1: 0.4379\n",
            "Epoch 39/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4595 - accuracy: 0.8191 - f1: 0.5654 - val_loss: 0.6866 - val_accuracy: 0.7626 - val_f1: 0.4805\n",
            "Epoch 40/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.4339 - accuracy: 0.8296 - f1: 0.6013 - val_loss: 0.7091 - val_accuracy: 0.7667 - val_f1: 0.4519\n",
            "Epoch 41/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4417 - accuracy: 0.8208 - f1: 0.5996 - val_loss: 0.6729 - val_accuracy: 0.7694 - val_f1: 0.4441\n",
            "Epoch 42/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.4254 - accuracy: 0.8440 - f1: 0.6082 - val_loss: 0.7210 - val_accuracy: 0.7681 - val_f1: 0.4762\n",
            "Epoch 43/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.4183 - accuracy: 0.8426 - f1: 0.6071 - val_loss: 0.6740 - val_accuracy: 0.7626 - val_f1: 0.4631\n",
            "Epoch 44/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.4108 - accuracy: 0.8447 - f1: 0.6098 - val_loss: 0.7146 - val_accuracy: 0.7517 - val_f1: 0.4520\n",
            "Epoch 45/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4067 - accuracy: 0.8406 - f1: 0.6127 - val_loss: 0.6847 - val_accuracy: 0.7490 - val_f1: 0.4565\n",
            "Epoch 46/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4208 - accuracy: 0.8433 - f1: 0.6132 - val_loss: 0.7018 - val_accuracy: 0.7585 - val_f1: 0.4771\n",
            "Epoch 47/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4150 - accuracy: 0.8436 - f1: 0.6155 - val_loss: 0.7158 - val_accuracy: 0.7640 - val_f1: 0.4494\n",
            "Epoch 48/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4043 - accuracy: 0.8443 - f1: 0.6359 - val_loss: 0.7187 - val_accuracy: 0.7558 - val_f1: 0.4639\n",
            "Epoch 49/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.4006 - accuracy: 0.8491 - f1: 0.6414 - val_loss: 0.7511 - val_accuracy: 0.7312 - val_f1: 0.4590\n",
            "Epoch 50/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3906 - accuracy: 0.8518 - f1: 0.6377 - val_loss: 0.7274 - val_accuracy: 0.7613 - val_f1: 0.4568\n",
            "Epoch 51/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3937 - accuracy: 0.8470 - f1: 0.6371 - val_loss: 0.7686 - val_accuracy: 0.7408 - val_f1: 0.4449\n",
            "Epoch 52/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.3743 - accuracy: 0.8590 - f1: 0.6617 - val_loss: 0.7915 - val_accuracy: 0.7490 - val_f1: 0.4471\n",
            "Epoch 53/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4022 - accuracy: 0.8481 - f1: 0.6356 - val_loss: 0.7487 - val_accuracy: 0.7653 - val_f1: 0.4642\n",
            "Epoch 54/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.4049 - accuracy: 0.8494 - f1: 0.6153 - val_loss: 0.7405 - val_accuracy: 0.7435 - val_f1: 0.4307\n",
            "Epoch 55/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3813 - accuracy: 0.8569 - f1: 0.6555 - val_loss: 0.7259 - val_accuracy: 0.7476 - val_f1: 0.4827\n",
            "Epoch 56/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3670 - accuracy: 0.8549 - f1: 0.6719 - val_loss: 0.7974 - val_accuracy: 0.7531 - val_f1: 0.4362\n",
            "Epoch 57/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3623 - accuracy: 0.8634 - f1: 0.6868 - val_loss: 0.7400 - val_accuracy: 0.7558 - val_f1: 0.4953\n",
            "Epoch 58/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3656 - accuracy: 0.8576 - f1: 0.6627 - val_loss: 0.7634 - val_accuracy: 0.7503 - val_f1: 0.4537\n",
            "Epoch 59/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3645 - accuracy: 0.8617 - f1: 0.6906 - val_loss: 0.7685 - val_accuracy: 0.7381 - val_f1: 0.4478\n",
            "Epoch 60/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.3572 - accuracy: 0.8665 - f1: 0.6834 - val_loss: 0.7688 - val_accuracy: 0.7517 - val_f1: 0.4473\n",
            "Epoch 61/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.3319 - accuracy: 0.8651 - f1: 0.6916 - val_loss: 0.7666 - val_accuracy: 0.7490 - val_f1: 0.4976\n",
            "Epoch 62/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3554 - accuracy: 0.8696 - f1: 0.6827 - val_loss: 0.7865 - val_accuracy: 0.7544 - val_f1: 0.4487\n",
            "Epoch 63/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.3375 - accuracy: 0.8744 - f1: 0.7059 - val_loss: 0.7829 - val_accuracy: 0.7626 - val_f1: 0.4797\n",
            "Epoch 64/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3531 - accuracy: 0.8668 - f1: 0.6871 - val_loss: 0.7455 - val_accuracy: 0.7476 - val_f1: 0.4695\n",
            "Epoch 65/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3299 - accuracy: 0.8727 - f1: 0.7072 - val_loss: 0.7656 - val_accuracy: 0.7394 - val_f1: 0.4784\n",
            "Epoch 66/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.3313 - accuracy: 0.8733 - f1: 0.7005 - val_loss: 0.8041 - val_accuracy: 0.7517 - val_f1: 0.4908\n",
            "Epoch 67/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.3547 - accuracy: 0.8679 - f1: 0.6949 - val_loss: 0.8110 - val_accuracy: 0.7490 - val_f1: 0.4523\n",
            "Epoch 68/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3327 - accuracy: 0.8733 - f1: 0.6964 - val_loss: 0.7721 - val_accuracy: 0.7435 - val_f1: 0.4999\n",
            "Epoch 69/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.3237 - accuracy: 0.8808 - f1: 0.7251 - val_loss: 0.8042 - val_accuracy: 0.7585 - val_f1: 0.4681\n",
            "Epoch 70/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3390 - accuracy: 0.8655 - f1: 0.6928 - val_loss: 0.7701 - val_accuracy: 0.7408 - val_f1: 0.4792\n",
            "Epoch 71/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3297 - accuracy: 0.8750 - f1: 0.6894 - val_loss: 0.7734 - val_accuracy: 0.7503 - val_f1: 0.4787\n",
            "Epoch 72/100\n",
            "92/92 [==============================] - 14s 148ms/step - loss: 0.2968 - accuracy: 0.8798 - f1: 0.7079 - val_loss: 0.7995 - val_accuracy: 0.7422 - val_f1: 0.4602\n",
            "Epoch 73/100\n",
            "92/92 [==============================] - 14s 147ms/step - loss: 0.3155 - accuracy: 0.8788 - f1: 0.7153 - val_loss: 0.7832 - val_accuracy: 0.7517 - val_f1: 0.4798\n",
            "Epoch 74/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3134 - accuracy: 0.8781 - f1: 0.7305 - val_loss: 0.7627 - val_accuracy: 0.7422 - val_f1: 0.4620\n",
            "Epoch 75/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.2921 - accuracy: 0.8853 - f1: 0.7356 - val_loss: 0.8164 - val_accuracy: 0.7462 - val_f1: 0.4921\n",
            "Epoch 76/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.3020 - accuracy: 0.8829 - f1: 0.7212 - val_loss: 0.8014 - val_accuracy: 0.7599 - val_f1: 0.5080\n",
            "Epoch 77/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.3181 - accuracy: 0.8867 - f1: 0.7361 - val_loss: 0.8477 - val_accuracy: 0.7503 - val_f1: 0.4481\n",
            "Epoch 78/100\n",
            "92/92 [==============================] - 14s 147ms/step - loss: 0.2914 - accuracy: 0.8914 - f1: 0.7240 - val_loss: 0.8228 - val_accuracy: 0.7585 - val_f1: 0.4939\n",
            "Epoch 79/100\n",
            "92/92 [==============================] - 14s 148ms/step - loss: 0.2948 - accuracy: 0.8822 - f1: 0.7328 - val_loss: 0.8069 - val_accuracy: 0.7544 - val_f1: 0.4849\n",
            "Epoch 80/100\n",
            "92/92 [==============================] - 14s 147ms/step - loss: 0.2987 - accuracy: 0.8887 - f1: 0.7390 - val_loss: 0.8074 - val_accuracy: 0.7626 - val_f1: 0.4879\n",
            "Epoch 81/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.2891 - accuracy: 0.8935 - f1: 0.7534 - val_loss: 0.8960 - val_accuracy: 0.7503 - val_f1: 0.4651\n",
            "Epoch 82/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.3008 - accuracy: 0.8894 - f1: 0.7117 - val_loss: 0.8729 - val_accuracy: 0.7490 - val_f1: 0.4751\n",
            "Epoch 83/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.2932 - accuracy: 0.8925 - f1: 0.7471 - val_loss: 0.8649 - val_accuracy: 0.7503 - val_f1: 0.4997\n",
            "Epoch 84/100\n",
            "92/92 [==============================] - 13s 147ms/step - loss: 0.2852 - accuracy: 0.8921 - f1: 0.7365 - val_loss: 0.8143 - val_accuracy: 0.7476 - val_f1: 0.4993\n",
            "Epoch 85/100\n",
            "92/92 [==============================] - 14s 147ms/step - loss: 0.2616 - accuracy: 0.8989 - f1: 0.7434 - val_loss: 0.8450 - val_accuracy: 0.7558 - val_f1: 0.4841\n",
            "Epoch 86/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.2637 - accuracy: 0.8996 - f1: 0.7551 - val_loss: 0.8135 - val_accuracy: 0.7544 - val_f1: 0.4786\n",
            "Epoch 87/100\n",
            "92/92 [==============================] - 14s 148ms/step - loss: 0.2693 - accuracy: 0.9003 - f1: 0.7636 - val_loss: 0.8043 - val_accuracy: 0.7544 - val_f1: 0.4901\n",
            "Epoch 88/100\n",
            "92/92 [==============================] - 14s 147ms/step - loss: 0.2730 - accuracy: 0.9027 - f1: 0.7551 - val_loss: 0.9168 - val_accuracy: 0.7490 - val_f1: 0.4746\n",
            "Epoch 89/100\n",
            "92/92 [==============================] - 13s 147ms/step - loss: 0.2852 - accuracy: 0.8928 - f1: 0.7468 - val_loss: 0.8210 - val_accuracy: 0.7517 - val_f1: 0.4952\n",
            "Epoch 90/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.2838 - accuracy: 0.8925 - f1: 0.7400 - val_loss: 0.8275 - val_accuracy: 0.7503 - val_f1: 0.4896\n",
            "Epoch 91/100\n",
            "92/92 [==============================] - 13s 145ms/step - loss: 0.2641 - accuracy: 0.9010 - f1: 0.7713 - val_loss: 0.8578 - val_accuracy: 0.7667 - val_f1: 0.5022\n",
            "Epoch 92/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.2741 - accuracy: 0.8938 - f1: 0.7561 - val_loss: 0.8703 - val_accuracy: 0.7558 - val_f1: 0.5010\n",
            "Epoch 93/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.2886 - accuracy: 0.8918 - f1: 0.7593 - val_loss: 0.7883 - val_accuracy: 0.7613 - val_f1: 0.4968\n",
            "Epoch 94/100\n",
            "92/92 [==============================] - 13s 144ms/step - loss: 0.2829 - accuracy: 0.8914 - f1: 0.7567 - val_loss: 0.9136 - val_accuracy: 0.7503 - val_f1: 0.5077\n",
            "Epoch 95/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.2599 - accuracy: 0.9088 - f1: 0.7666 - val_loss: 0.9210 - val_accuracy: 0.7517 - val_f1: 0.4642\n",
            "Epoch 96/100\n",
            "92/92 [==============================] - 13s 146ms/step - loss: 0.2648 - accuracy: 0.9065 - f1: 0.7803 - val_loss: 0.9185 - val_accuracy: 0.7435 - val_f1: 0.4719\n",
            "Epoch 97/100\n",
            "92/92 [==============================] - 14s 147ms/step - loss: 0.2604 - accuracy: 0.9068 - f1: 0.7585 - val_loss: 0.8614 - val_accuracy: 0.7422 - val_f1: 0.4771\n",
            "Epoch 98/100\n",
            "92/92 [==============================] - 14s 147ms/step - loss: 0.2446 - accuracy: 0.9092 - f1: 0.7711 - val_loss: 0.8689 - val_accuracy: 0.7599 - val_f1: 0.4959\n",
            "Epoch 99/100\n",
            "92/92 [==============================] - 14s 148ms/step - loss: 0.2367 - accuracy: 0.9133 - f1: 0.7902 - val_loss: 0.8656 - val_accuracy: 0.7449 - val_f1: 0.5000\n",
            "Epoch 100/100\n",
            "92/92 [==============================] - 13s 147ms/step - loss: 0.2427 - accuracy: 0.9123 - f1: 0.7807 - val_loss: 0.9925 - val_accuracy: 0.7558 - val_f1: 0.4865\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "def create_datagen():\n",
        "    return ImageDataGenerator(\n",
        "        horizontal_flip=True,   # randomly flip images\n",
        "        vertical_flip=True,     # randomly flip images\n",
        "\n",
        "        preprocessing_function = preprocess_image\n",
        "    )\n",
        "    \n",
        "# Using original generator\n",
        "data_generator = create_datagen().flow(x_train, y_train,batch_size=32)\n",
        "print(\"Image data augmentated ...\")\n",
        "\n",
        "def spatial_attention(input_tensor):\n",
        "    x = Conv2D(1, kernel_size=7, strides=1, padding='same', activation='sigmoid')(input_tensor)\n",
        "    return Multiply()([input_tensor, x])\n",
        "\n",
        "def channel_attention(input_tensor):\n",
        "    x = GlobalAveragePooling2D()(input_tensor)\n",
        "    x = Dense(K.int_shape(input_tensor)[-1] // 4, activation='relu')(x)\n",
        "    x = Dense(K.int_shape(input_tensor)[-1], activation='sigmoid')(x)\n",
        "    x = Reshape((1, 1, K.int_shape(input_tensor)[-1]))(x)\n",
        "    return Multiply()([input_tensor, x])\n",
        "\n",
        "def efficientnet_sa(num_classes):\n",
        "    base_model = EfficientNetB3(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "    x = base_model.output\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = spatial_attention(x)\n",
        "    x = channel_attention(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = keras.models.Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split data into train and validation sets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(32)\n",
        "\n",
        "# f1 score\n",
        "# import tensorflow.compat.v1 as tf\n",
        "# tf.disable_v2_behavior() \n",
        "import keras.backend as K\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    y_pred = K.round(y_pred)\n",
        "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
        "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
        "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
        "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
        "\n",
        "    p = tp / (tp + fp + K.epsilon())\n",
        "    r = tp / (tp + fn + K.epsilon())\n",
        "\n",
        "    f1 = 2*p*r / (p+r+K.epsilon())\n",
        "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
        "    return K.mean(f1)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Create model\n",
        "model = efficientnet_sa(num_classes=5)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=AdamW(lr=0.0001), metrics=['accuracy',f1])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(train_dataset, epochs=100, validation_data=test_dataset)\n",
        "\n",
        "# Evaluate model on test set\n",
        "# test_loss, test_acc = model.evaluate(test_dataset)\n",
        "# print('Test loss:', test_loss)\n",
        "# print('Test accuracy:', test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# convert the history.history dict to a pandas DataFrame:     \n",
        "import pandas as pd\n",
        "hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "#  saving history to csv file\n",
        "hist_csv_file = '/content/drive/MyDrive/efficientnet_attention_model/efficientnet_attention_history.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n",
        "\n",
        "# saving the model\n",
        "model.save('/content/drive/MyDrive/efficientnet_attention_model/efficientnet_attention.h5')\n"
      ],
      "metadata": {
        "id": "PK44wNpqBviv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdCybYNMe77n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}